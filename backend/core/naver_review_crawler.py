#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ë¦¬ë·° í¬ë¡¤ë§ ì—”ì§„
- ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° í˜ì´ì§€ ìë™ ìˆ˜ì§‘
- ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, í‚¤ì›Œë“œ, í‰ì  í†µí•© ì¶”ì¶œ
- "ë”ë³´ê¸°" ë²„íŠ¼ ìë™ í´ë¦­ìœ¼ë¡œ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
"""

import os
import sys
import json
import asyncio
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Any
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError
from supabase import create_client, Client
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ Python pathì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

from naver_login_auto import NaverAutoLogin

class NaverReviewCrawler:
    def __init__(self, headless=True, timeout=30000, force_fresh_login=False):
        self.headless = headless
        self.timeout = timeout
        self.force_fresh_login = force_fresh_login
        self.login_system = NaverAutoLogin(
            headless=headless, 
            timeout=timeout, 
            force_fresh_login=force_fresh_login
        )
        
        # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (Service Role Key ì‚¬ìš© - RLS ìš°íšŒ)
        load_dotenv()
        supabase_url = os.getenv('NEXT_PUBLIC_SUPABASE_URL')
        supabase_service_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
        
        if not supabase_url or not supabase_service_key:
            raise ValueError("Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. NEXT_PUBLIC_SUPABASE_URLê³¼ SUPABASE_SERVICE_ROLE_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        self.supabase: Client = create_client(supabase_url, supabase_service_key)
    
    async def _close_popup_if_exists(self, page) -> bool:
        """ë¦¬ë·° í˜ì´ì§€ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” íŒì—… ë‹«ê¸°"""
        try:
            print("íŒì—… í™•ì¸ ë° ë‹«ê¸° ì²˜ë¦¬ ì¤‘...")
            
            # ë‹¤ì–‘í•œ íŒì—… ë‹«ê¸° ë²„íŠ¼ ì„ íƒìë“¤
            popup_close_selectors = [
                "i.fn-booking.fn-booking-close1",           # ì‚¬ìš©ìê°€ ì œê³µí•œ ì„ íƒì
                ".fn-booking-close1",                       # í´ë˜ìŠ¤ë§Œ
                "i[aria-label='ë‹«ê¸°']",                     # aria-label ì†ì„±
                ".popup_close",                             # ì¼ë°˜ì ì¸ íŒì—… ë‹«ê¸°
                ".modal_close",                             # ëª¨ë‹¬ ë‹«ê¸°
                "button[class*='close']",                   # ë‹«ê¸° ë²„íŠ¼
                ".btn_close",                               # ë²„íŠ¼ íƒ€ì… ë‹«ê¸°
                "[data-action='close']",                    # ë°ì´í„° ì•¡ì…˜
                ".layer_close"                              # ë ˆì´ì–´ ë‹«ê¸°
            ]
            
            for selector in popup_close_selectors:
                try:
                    # íŒì—… ìš”ì†Œê°€ ìˆëŠ”ì§€ í™•ì¸ (ì§§ì€ íƒ€ì„ì•„ì›ƒ)
                    close_button = await page.wait_for_selector(selector, timeout=2000)
                    if close_button:
                        # ìš”ì†Œê°€ ì‹¤ì œë¡œ ë³´ì´ëŠ”ì§€ í™•ì¸
                        is_visible = await close_button.is_visible()
                        if is_visible:
                            print(f"íŒì—… ë‹«ê¸° ë²„íŠ¼ ë°œê²¬: {selector}")
                            await close_button.click()
                            await page.wait_for_timeout(1000)  # íŒì—… ë‹«í˜ ëŒ€ê¸°
                            print("íŒì—… ë‹«ê¸° ì™„ë£Œ")
                            return True
                except Exception:
                    # ì´ ì„ íƒìë¡œëŠ” íŒì—…ì„ ì°¾ì§€ ëª»í•¨, ë‹¤ìŒ ì‹œë„
                    continue
                    
            print("íŒì—…ì´ ì—†ê±°ë‚˜ ì´ë¯¸ ë‹«í˜€ìˆìŒ")
            return False
            
        except Exception as e:
            print(f"íŒì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
        
    async def crawl_reviews(self, platform_id: str, platform_password: str, 
                           store_id: str, user_id: str, days: int = 7) -> Dict:
        """ë¦¬ë·° í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜"""
        try:
            print(f"Starting review crawling for store: {store_id}")
            
            # ë¡œê·¸ì¸ ì²˜ë¦¬ ë° ë¸Œë¼ìš°ì € ì„¸ì…˜ ìœ ì§€ (ë§¤ì¥ í¬ë¡¤ë§ ë¹„í™œì„±í™”)
            login_result = await self.login_system.login(
                platform_id, 
                platform_password, 
                keep_browser_open=True,
                crawl_stores=False  # ë¦¬ë·° í¬ë¡¤ëŸ¬ëŠ” ë§¤ì¥ í¬ë¡¤ë§ ë¶ˆí•„ìš”
            )
            if not login_result['success']:
                return {
                    'success': False,
                    'error': f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {login_result.get('error', 'Unknown error')}",
                    'reviews_found': 0,
                    'reviews_new': 0,
                    'reviews_updated': 0
                }
            
            print("ë¡œê·¸ì¸ ì„±ê³µ - ë™ì¼í•œ ë¸Œë¼ìš°ì € ì„¸ì…˜ì—ì„œ ë¦¬ë·° í˜ì´ì§€ ì ‘ì† ì¤‘...")
            
            # ê¸°ì¡´ ë¸Œë¼ìš°ì € ì„¸ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·° í˜ì´ì§€ í¬ë¡¤ë§
            browser = login_result['browser']
            playwright = login_result['playwright'] 
            page = login_result['page']
            
            try:
                # ë¸Œë¼ìš°ì € ì—°ê²° ìƒíƒœ í™•ì¸ (í˜ì´ì§€ê°€ ìœ íš¨í•œì§€ í™•ì¸)
                try:
                    current_url = page.url  # í˜ì´ì§€ ìƒíƒœ í™•ì¸
                    print(f"ë¸Œë¼ìš°ì € ì—°ê²° ìƒíƒœ ì–‘í˜¸ - í˜„ì¬ URL: {current_url}")
                    print("í¬ë¡¤ë§ ì‹œì‘")
                    reviews = await self._crawl_review_page_with_session(browser, page, store_id, days)
                    return await self._process_review_results(reviews, store_id, user_id)
                except Exception as connection_error:
                    print(f"ë¸Œë¼ìš°ì € ì—°ê²°ì´ ëŠì–´ì§: {str(connection_error)}")
                    return {
                        'success': False,
                        'error': f'ë¸Œë¼ìš°ì € ì—°ê²° ì˜¤ë¥˜: {str(connection_error)}',
                        'reviews_found': 0,
                        'reviews_new': 0,
                        'reviews_updated': 0
                    }
            except Exception as e:
                print(f"í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return {
                    'success': False,
                    'error': str(e),
                    'reviews_found': 0,
                    'reviews_new': 0,
                    'reviews_updated': 0
                }
            finally:
                # í¬ë¡¤ë§ ì™„ë£Œ í›„ ë¸Œë¼ìš°ì € ì •ë¦¬
                try:
                    if browser:
                        await browser.close()
                    if playwright:
                        await playwright.stop()
                except Exception as e:
                    print(f"ë¸Œë¼ìš°ì € ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
        except Exception as e:
            print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'reviews_found': 0,
                'reviews_new': 0,
                'reviews_updated': 0
            }
    
    async def _crawl_review_page_with_session(self, browser, page, store_id: str, days: int) -> List[Dict]:
        """ê¸°ì¡´ ë¸Œë¼ìš°ì € ì„¸ì…˜ì„ ì‚¬ìš©í•œ ë¦¬ë·° í˜ì´ì§€ í¬ë¡¤ë§"""
        try:
            # ë¦¬ë·° í˜ì´ì§€ URL ìƒì„± (ì§€ì •ëœ store_id ì‚¬ìš©)
            review_url = f"https://new.smartplace.naver.com/bizes/place/{store_id}/reviews"
            print(f"âœ… ì§€ì •ëœ ë§¤ì¥ IDë¡œ ì§ì ‘ ì´ë™: {store_id}")
            print(f"ë¦¬ë·° í˜ì´ì§€ URL: {review_url}")
            
            # ìµœì í™”: ì§ì ‘ ë¦¬ë·° í˜ì´ì§€ë¡œ ì´ë™ (ëŒ€ê¸°ì‹œê°„ ë‹¨ì¶•)
            await page.goto(review_url, wait_until='domcontentloaded', timeout=self.timeout)
            await page.wait_for_timeout(3000)  # ìµœì í™”: ëŒ€ê¸°ì‹œê°„ ë‹¨ì¶• (networkidle ëŒ€ì‹  3ì´ˆ ê³ ì •)
            
            print(f"âœ… ë¦¬ë·° í˜ì´ì§€ ì ‘ì† ì™„ë£Œ: {review_url}")
            
            # íŒì—… ë‹«ê¸° ì²˜ë¦¬ (ë¦¬ë·° í˜ì´ì§€ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” íŒì—…)
            await self._close_popup_if_exists(page)
            
            # ë‚ ì§œ í•„í„° ì„¤ì •
            await self._set_date_filter(page, days)
            
            # ë¦¬ë·° ìˆ˜ì§‘
            reviews = await self._extract_reviews(page)
            
            print(f"ìˆ˜ì§‘ëœ ë¦¬ë·° ìˆ˜: {len(reviews)}")
            return reviews
            
        except Exception as e:
            print(f"ë¦¬ë·° í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def _crawl_review_page(self, profile_path: str, store_id: str, days: int) -> List[Dict]:
        """ë¦¬ë·° í˜ì´ì§€ í¬ë¡¤ë§"""
        browser = None
        playwright = None
        
        try:
            # ë¸Œë¼ìš°ì € ì„¤ì • (ë¡œê·¸ì¸ ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ í”„ë¡œí•„ ì‚¬ìš©)
            playwright = await async_playwright().start()
            
            # ë¡œê·¸ì¸ ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ ë¸Œë¼ìš°ì € arguments ì‚¬ìš©
            browser_args = [
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--disable-extensions',
                '--disable-gpu',
                '--disable-web-security',
                '--no-sandbox',
                '--disable-features=VizDisplayCompositor'
            ]
            
            browser = await playwright.chromium.launch_persistent_context(
                user_data_dir=profile_path,
                headless=self.headless,
                args=browser_args,
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                locale='ko-KR',
                timezone_id='Asia/Seoul',
                viewport={'width': 1280, 'height': 720},
                java_script_enabled=True,
                accept_downloads=True,
                ignore_https_errors=True
            )
            
            page = browser.pages[0] if browser.pages else await browser.new_page()
            
            # ë¦¬ë·° í˜ì´ì§€ URL ìƒì„± (ì§€ì •ëœ store_id ì‚¬ìš©)
            review_url = f"https://new.smartplace.naver.com/bizes/place/{store_id}/reviews"
            print(f"âœ… ì§€ì •ëœ ë§¤ì¥ IDë¡œ ì§ì ‘ ì´ë™: {store_id}")
            print(f"ë¦¬ë·° í˜ì´ì§€ URL: {review_url}")
            
            # ìµœì í™”: ì§ì ‘ ë¦¬ë·° í˜ì´ì§€ë¡œ ì´ë™ (ëŒ€ê¸°ì‹œê°„ ë‹¨ì¶•)
            await page.goto(review_url, wait_until='domcontentloaded', timeout=self.timeout)
            await page.wait_for_timeout(3000)  # ìµœì í™”: ëŒ€ê¸°ì‹œê°„ ë‹¨ì¶• (networkidle ëŒ€ì‹  3ì´ˆ ê³ ì •)
            
            print(f"âœ… ë¦¬ë·° í˜ì´ì§€ ì ‘ì† ì™„ë£Œ: {review_url}")
            
            # ë‚ ì§œ í•„í„° ì„¤ì •
            await self._set_date_filter(page, days)
            
            # ë¦¬ë·° ìˆ˜ì§‘
            reviews = await self._extract_reviews(page)
            
            print(f"ìˆ˜ì§‘ëœ ë¦¬ë·° ìˆ˜: {len(reviews)}")
            return reviews
            
        except Exception as e:
            print(f"ë¦¬ë·° í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
        finally:
            if browser:
                await browser.close()
            if playwright:
                await playwright.stop()
    
    async def _set_date_filter(self, page, days: int):
        """ë‚ ì§œ í•„í„° ì„¤ì •"""
        try:
            print(f"ë‚ ì§œ í•„í„° ì„¤ì •: ìµœê·¼ {days}ì¼")
            
            # ë‚ ì§œ ë“œë¡­ë°•ìŠ¤ í´ë¦­
            date_selector = "button.ButtonSelector_btn_select__BcLKR[data-area-code='rv.calendarfilter']"
            await page.wait_for_selector(date_selector, timeout=self.timeout)
            await page.click(date_selector)
            await page.wait_for_timeout(1000)
            
            # í•„í„° ì˜µì…˜ ì„ íƒ
            if days <= 7:
                # 7ì¼ ì„ íƒ
                await page.click("a[data-area-code='rv.calendarweek']")
            else:
                # í•œë‹¬ ì„ íƒ
                await page.click("a[data-area-code='rv.calendarmonth']")
            
            await page.wait_for_timeout(2000)
            print("ë‚ ì§œ í•„í„° ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            print(f"ë‚ ì§œ í•„í„° ì„¤ì • ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # í•„í„° ì„¤ì • ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    
    async def _extract_reviews(self, page) -> List[Dict]:
        """ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ (ë¬´í•œ ìŠ¤í¬ë¡¤ë¡œ ëª¨ë“  ë¦¬ë·° ë¡œë“œ)"""
        reviews = []
        
        try:
            # ë¦¬ë·° ëª©ë¡ ë¡œë“œ ëŒ€ê¸°
            await page.wait_for_timeout(3000)
            
            # ë¦¬ë·° ì•„ì´í…œ ì„ íƒì
            review_selector = "li.pui__X35jYm.Review_pui_review__zhZdn"
            await page.wait_for_selector(review_selector, timeout=10000)
            
            # ë¬´í•œ ìŠ¤í¬ë¡¤ë¡œ ëª¨ë“  ë¦¬ë·° ë¡œë“œ
            max_scroll_attempts = 30  # ìµœëŒ€ 30ë²ˆê¹Œì§€ ìŠ¤í¬ë¡¤
            no_new_content_count = 0  # ìƒˆ ì½˜í…ì¸ ê°€ ì—†ëŠ” íšŸìˆ˜
            
            for attempt in range(max_scroll_attempts):
                try:
                    # í˜„ì¬ ë¦¬ë·° ìˆ˜ í™•ì¸
                    current_reviews = await page.query_selector_all(review_selector)
                    current_count = len(current_reviews)
                    print(f"ìŠ¤í¬ë¡¤ {attempt + 1}: í˜„ì¬ ë¡œë“œëœ ë¦¬ë·° ìˆ˜ {current_count}")
                    
                    # í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
                    await page.evaluate("""
                        window.scrollTo(0, document.body.scrollHeight);
                    """)
                    
                    # ìŠ¤í¬ë¡¤ í›„ ë¡œë”© ëŒ€ê¸°
                    await page.wait_for_timeout(2000)
                    
                    # ìƒˆë¡œìš´ ë¦¬ë·°ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    new_reviews = await page.query_selector_all(review_selector)
                    new_count = len(new_reviews)
                    
                    if new_count > current_count:
                        # ìƒˆë¡œìš´ ë¦¬ë·°ê°€ ë¡œë“œë¨
                        print(f"ìƒˆ ë¦¬ë·° {new_count - current_count}ê°œ ë¡œë“œë¨")
                        no_new_content_count = 0
                    else:
                        # ìƒˆë¡œìš´ ë¦¬ë·°ê°€ ì—†ìŒ
                        no_new_content_count += 1
                        print(f"ìƒˆ ë¦¬ë·° ì—†ìŒ (ì—°ì† {no_new_content_count}ë²ˆ)")
                        
                        # 3ë²ˆ ì—°ì† ìƒˆ ì½˜í…ì¸ ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                        if no_new_content_count >= 3:
                            print("ë” ì´ìƒ ë¡œë“œí•  ë¦¬ë·°ê°€ ì—†ìŒ - ìŠ¤í¬ë¡¤ ì™„ë£Œ")
                            break
                    
                    # ì¶”ê°€ ë¡œë”© í™•ì¸ì„ ìœ„í•œ ëŒ€ê¸°
                    await page.wait_for_timeout(1000)
                    
                except Exception as e:
                    print(f"ìŠ¤í¬ë¡¤ ì¤‘ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {str(e)}")
                    break
            
            # ìµœì¢… ë¦¬ë·° ìš”ì†Œë“¤ ê°€ì ¸ì˜¤ê¸°
            final_review_elements = await page.query_selector_all(review_selector)
            final_count = len(final_review_elements)
            print(f"ìµœì¢… ë°œê²¬ëœ ë¦¬ë·° ìš”ì†Œ ìˆ˜: {final_count}")
            
            # ëª¨ë“  ë¦¬ë·° ì¶”ì¶œ
            for i, review_element in enumerate(final_review_elements):
                try:
                    print(f"ë¦¬ë·° {i+1}/{final_count} ì²˜ë¦¬ ì¤‘...")
                    review_data = await self._extract_single_review(review_element, page)
                    if review_data:
                        reviews.append(review_data)
                        print(f"ë¦¬ë·° {i+1} ì¶”ì¶œ ì™„ë£Œ")
                except Exception as e:
                    print(f"ë¦¬ë·° {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue
            
            print(f"ì´ {len(reviews)}ê°œ ë¦¬ë·° ì¶”ì¶œ ì™„ë£Œ")
            
            # ë‹µê¸€ ìƒíƒœë³„ í†µê³„ ì¶œë ¥
            self._print_reply_statistics(reviews)
            
            return reviews
            
        except Exception as e:
            print(f"ë¦¬ë·° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return reviews
    
    def _print_reply_statistics(self, reviews: List[Dict]) -> None:
        """ë‹µê¸€ ìƒíƒœë³„ í†µê³„ ì¶œë ¥"""
        try:
            total_reviews = len(reviews)
            if total_reviews == 0:
                return
            
            # ë‹µê¸€ ìƒíƒœë³„ ì¹´ìš´íŠ¸
            sent_count = 0
            draft_count = 0
            unknown_count = 0
            
            for review in reviews:
                reply_status = review.get('reply_status')
                if reply_status == 'sent':
                    sent_count += 1
                elif reply_status == 'draft':
                    draft_count += 1
                else:
                    unknown_count += 1
            
            # í†µê³„ ì¶œë ¥
            print("\n" + "="*50)
            print("ğŸ“Š ë‹µê¸€ ìƒíƒœ í†µê³„")
            print("="*50)
            print(f"ğŸ“ ì´ ë¦¬ë·° ìˆ˜: {total_reviews}ê°œ")
            print(f"âœ… ë‹µê¸€ ì™„ë£Œ: {sent_count}ê°œ ({sent_count/total_reviews*100:.1f}%)")
            print(f"â³ ë‹µê¸€ ëŒ€ê¸°: {draft_count}ê°œ ({draft_count/total_reviews*100:.1f}%)")
            if unknown_count > 0:
                print(f"â“ ìƒíƒœ ë¶ˆëª…: {unknown_count}ê°œ ({unknown_count/total_reviews*100:.1f}%)")
            
            # ë‹µê¸€ ì‘ì„±ë¥ 
            if total_reviews > 0:
                reply_rate = sent_count / total_reviews * 100
                print(f"ğŸ“ˆ ë‹µê¸€ ì‘ì„±ë¥ : {reply_rate:.1f}%")
            
            print("="*50 + "\n")
            
        except Exception as e:
            print(f"ë‹µê¸€ í†µê³„ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    async def _extract_single_review(self, review_element, page) -> Optional[Dict]:
        """ê°œë³„ ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ"""
        try:
            review_data = {}
            
            # ì‘ì„±ì ì •ë³´
            reviewer_info = await self._extract_reviewer_info(review_element)
            review_data.update(reviewer_info)
            
            # ë‚ ì§œ ì •ë³´
            date_info = await self._extract_date_info(review_element)
            review_data.update(date_info)
            
            # ë¦¬ë·° ë‚´ìš© (ë”ë³´ê¸° ì²˜ë¦¬ í¬í•¨)
            review_content = await self._extract_review_content(review_element, page)
            review_data.update(review_content)
            
            # ì´ë¯¸ì§€ ì •ë³´
            images = await self._extract_review_images(review_element)
            review_data['images'] = images
            
            # í‚¤ì›Œë“œ ì •ë³´ (ë”ë³´ê¸° ì²˜ë¦¬ í¬í•¨)
            keywords = await self._extract_review_keywords(review_element, page)
            review_data['keywords'] = keywords
            
            # ì‚¬ì—…ì ë‹µê¸€ ë° ìƒíƒœ ì¶”ì¶œ (ë”ë³´ê¸° ì²˜ë¦¬ í¬í•¨)
            reply_info = await self._extract_store_reply(review_element, page)
            review_data['reply_text'] = reply_info.get('reply_text')
            review_data['reply_status'] = reply_info.get('reply_status')
            
            # ë””ë²„ê¹…ì„ ìœ„í•œ HTML êµ¬ì¡° ì¶œë ¥ (ì²« ë²ˆì§¸ ë¦¬ë·°ë§Œ)
            if not hasattr(self, '_debug_html_printed'):
                try:
                    html_content = await review_element.inner_html()
                    print(f"=== ì²« ë²ˆì§¸ ë¦¬ë·° HTML êµ¬ì¡° ë””ë²„ê¹… ===")
                    print(html_content[:2000])  # ì²˜ìŒ 2000ìë§Œ ì¶œë ¥
                    print("=== HTML êµ¬ì¡° ë””ë²„ê¹… ë ===")
                    self._debug_html_printed = True
                except:
                    pass
            
            # ê¸°íƒ€ ì •ë³´
            review_data['has_receipt'] = await self._check_receipt(review_element)
            review_data['review_id'] = await self._generate_review_id(review_element)
            
            return review_data
            
        except Exception as e:
            print(f"ê°œë³„ ë¦¬ë·° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _extract_reviewer_info(self, review_element) -> Dict:
        """ì‘ì„±ì ì •ë³´ ì¶”ì¶œ"""
        try:
            reviewer_info = {}
            
            # ì‘ì„±ì ì´ë¦„
            name_element = await review_element.query_selector(".pui__NMi-Dp")
            if name_element:
                reviewer_info['reviewer_name'] = await name_element.text_content()
            
            # ì‘ì„±ì í†µê³„ (ë¦¬ë·° ìˆ˜, ì‚¬ì§„ ìˆ˜, ë°©ë¬¸ íšŸìˆ˜)
            stats_elements = await review_element.query_selector_all(".pui__WN-kAf")
            stats = {}
            for stat_element in stats_elements:
                stat_text = await stat_element.text_content()
                if 'ë¦¬ë·°' in stat_text:
                    stats['review_count'] = self._extract_number(stat_text)
                elif 'ì‚¬ì§„' in stat_text:
                    stats['photo_count'] = self._extract_number(stat_text)
                elif 'ë°©ë¬¸' in stat_text:
                    stats['visit_count'] = self._extract_number(stat_text)
            
            reviewer_info['reviewer_stats'] = stats
            
            # ì‘ì„±ì í”„ë¡œí•„ URL
            profile_link = await review_element.query_selector("a[data-pui-click-code='profile']")
            if profile_link:
                reviewer_info['reviewer_profile_url'] = await profile_link.get_attribute('href')
            
            return reviewer_info
            
        except Exception as e:
            print(f"ì‘ì„±ì ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    async def _extract_date_info(self, review_element) -> Dict:
        """ë‚ ì§œ ì •ë³´ ì¶”ì¶œ"""
        try:
            date_info = {}
            
            # ë°©ë¬¸ì¼ê³¼ ì‘ì„±ì¼ ì°¾ê¸°
            date_sections = await review_element.query_selector_all(".pui__4rEbt5")
            for section in date_sections:
                label_element = await section.query_selector(".pui__ewpNGR")
                if label_element:
                    label_text = await label_element.text_content()
                    time_element = await section.query_selector("time")
                    
                    if time_element:
                        date_text = await time_element.text_content()
                        
                        if 'ë°©ë¬¸ì¼' in label_text:
                            date_info['visit_date'] = self._parse_date(date_text)
                        elif 'ì‘ì„±ì¼' in label_text:
                            date_info['created_date'] = self._parse_date(date_text)
            
            return date_info
            
        except Exception as e:
            print(f"ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    async def _extract_review_content(self, review_element, page) -> Dict:
        """ë¦¬ë·° ë‚´ìš© ì¶”ì¶œ (ë”ë³´ê¸° ì²˜ë¦¬ í¬í•¨)"""
        try:
            content_info = {}
            
            # ë¦¬ë·° í…ìŠ¤íŠ¸ ì˜ì—­ ì°¾ê¸°
            text_container = await review_element.query_selector(".pui__vn15t2")
            if not text_container:
                # ì‚¬ì§„ë§Œ ìˆëŠ” ë¦¬ë·°ì˜ ê²½ìš° ë‹¤ë¥¸ ì„ íƒì ì‹œë„
                text_link = await review_element.query_selector("a.pui__xtsQN-[data-pui-click-code='text']")
                if text_link:
                    content_info['review_text'] = await text_link.text_content()
                return content_info
            
            # ë”ë³´ê¸° ë²„íŠ¼ í™•ì¸ ë° í´ë¦­
            more_button = await text_container.query_selector("a.pui__wFzIYl[aria-expanded='false']")
            if more_button:
                print("ë”ë³´ê¸° ë²„íŠ¼ ë°œê²¬ - í´ë¦­ ì¤‘...")
                await more_button.click()
                await page.wait_for_timeout(1000)
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_element = await text_container.query_selector("a.pui__xtsQN-")
            if text_element:
                review_text = await text_element.text_content()
                content_info['review_text'] = review_text.strip()
            
            # í‰ì  ì¶”ì¶œ (ë³„ì )
            rating = await self._extract_rating(review_element)
            if rating:
                content_info['rating'] = rating
            
            return content_info
            
        except Exception as e:
            print(f"ë¦¬ë·° ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    async def _extract_review_images(self, review_element) -> List[str]:
        """ë¦¬ë·° ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
        try:
            images = []
            
            # ì´ë¯¸ì§€ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
            image_container = await review_element.query_selector(".Review_img_slide__H3Xlr")
            if not image_container:
                return images
            
            # ëª¨ë“  ì´ë¯¸ì§€ ìš”ì†Œ ì¶”ì¶œ
            img_elements = await image_container.query_selector_all("img.Review_img__n9UPw")
            for img_element in img_elements:
                src = await img_element.get_attribute('src')
                if src and src.startswith('http'):
                    images.append(src)
            
            return images
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def _extract_review_keywords(self, review_element, page) -> List[str]:
        """ë¦¬ë·° í‚¤ì›Œë“œ ì¶”ì¶œ (ë”ë³´ê¸° ì²˜ë¦¬ í¬í•¨)"""
        try:
            keywords = []
            
            # í‚¤ì›Œë“œ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
            keyword_container = await review_element.query_selector(".pui__HLNvmI")
            if not keyword_container:
                return keywords
            
            # ë”ë³´ê¸° ë²„íŠ¼ í™•ì¸ ë° í´ë¦­
            more_keywords_button = await keyword_container.query_selector("a.pui__jhpEyP.pui__ggzZJ8[data-pui-click-code='rv.keywordmore']")
            if more_keywords_button:
                print("í‚¤ì›Œë“œ ë”ë³´ê¸° ë²„íŠ¼ ë°œê²¬ - í´ë¦­ ì¤‘...")
                await more_keywords_button.click()
                await page.wait_for_timeout(1000)
            
            # ëª¨ë“  í‚¤ì›Œë“œ ì¶”ì¶œ
            keyword_elements = await keyword_container.query_selector_all("span.pui__jhpEyP:not(.pui__ggzZJ8)")
            for keyword_element in keyword_elements:
                keyword_text = await keyword_element.text_content()
                if keyword_text and keyword_text.strip():
                    # ì´ëª¨ì§€ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                    clean_keyword = keyword_text.strip()
                    if clean_keyword and not clean_keyword.startswith('+'):
                        keywords.append(clean_keyword)
            
            return keywords
            
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def _extract_rating(self, review_element) -> Optional[int]:
        """í‰ì  ì¶”ì¶œ"""
        try:
            # ë³„ì ì€ ë³´í†µ ë‹¤ë¥¸ ìœ„ì¹˜ì— ìˆì„ ìˆ˜ ìˆìŒ
            # ì´ ë¶€ë¶„ì€ ì‹¤ì œ HTML êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”
            return None  # í˜„ì¬ëŠ” ë³„ì  ì •ë³´ê°€ ëª…í™•í•˜ì§€ ì•ŠìŒ
            
        except Exception as e:
            print(f"í‰ì  ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _extract_store_reply(self, review_element, page) -> Dict[str, Any]:
        """ì‚¬ì—…ì ë‹µê¸€ ë° ìƒíƒœ ì¶”ì¶œ (ë”ë³´ê¸° ì²˜ë¦¬ í¬í•¨)"""
        try:
            
            # ê²°ê³¼ ì´ˆê¸°í™”
            result = {
                'reply_text': None,
                'reply_status': None
            }
            
            # 1. ë¨¼ì € ë‹µê¸€ ì‘ì„± ë²„íŠ¼ í™•ì¸ (ë¯¸ë‹µë³€ ë¦¬ë·°)
            reply_write_btn = await review_element.query_selector("button[data-area-code='rv.replywrite']")
            if reply_write_btn:
                print("ğŸ“ ë¯¸ë‹µë³€ ë¦¬ë·° ë°œê²¬ - reply_status: draft")
                result['reply_status'] = 'draft'
                return result
            
            # 2. ë‹µê¸€ ìˆ˜ì • ë²„íŠ¼ í™•ì¸ (ë‹µë³€ ì™„ë£Œ ë¦¬ë·°)
            reply_edit_btn = await review_element.query_selector("a[data-pui-click-code='rv.replyedit']")
            if reply_edit_btn:
                print("âœ… ë‹µë³€ ì™„ë£Œ ë¦¬ë·° ë°œê²¬ - reply_status: sent")
                result['reply_status'] = 'sent'
                
                # ë‹µê¸€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                # ë‹µê¸€ ì„¹ì…˜ ì°¾ê¸°
                reply_section_selectors = [
                    ".pui__GbW8H7.pui__BDGQvd",  # ë‹µê¸€ ì„¹ì…˜ ì „ì²´
                    ".pui__GbW8H7",  # ë‹µê¸€ ì„¹ì…˜ (ë‹¨ì¼ í´ë˜ìŠ¤)
                    "div:has(span.pui__XE54q7)",  # ì‚¬ì—…ìëª… í¬í•¨í•œ ì„¹ì…˜
                ]
                
                reply_section = None
                for selector in reply_section_selectors:
                    try:
                        reply_section = await review_element.query_selector(selector)
                        if reply_section:
                            print(f"ë‹µê¸€ ì„¹ì…˜ ë°œê²¬ (ì„ íƒì: {selector})")
                            break
                    except:
                        continue
                
                if reply_section:
                    # ë‹µê¸€ í…ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
                    reply_text_selectors = [
                        "a.pui__xtsQN-[data-pui-click-code='rv.replyfold']",  # ì •í™•í•œ íŒ¨í„´
                        ".pui__J0tczd a.pui__xtsQN-",  # ì»¨í…Œì´ë„ˆ ë‚´ í…ìŠ¤íŠ¸ ë§í¬
                        "a[data-pui-click-code='rv.replyfold']",  # data ì†ì„± ê¸°ë°˜
                    ]
                    
                    reply_text_container = None
                    for selector in reply_text_selectors:
                        try:
                            reply_text_container = await reply_section.query_selector(selector)
                            if reply_text_container:
                                print(f"ë‹µê¸€ í…ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ë°œê²¬ (ì„ íƒì: {selector})")
                                break
                        except:
                            continue
                    
                    if reply_text_container:
                        # ë”ë³´ê¸° ë²„íŠ¼ ì²˜ë¦¬
                        more_button_selectors = [
                            "a.pui__wFzIYl[aria-expanded='false'][data-pui-click-code='rv.replyfold']",
                            "a.pui__wFzIYl[aria-expanded='false']",
                            ".pui__J0tczd a.pui__wFzIYl",
                            "a.pui__wFzIYl",
                        ]
                        
                        more_reply_button = None
                        for selector in more_button_selectors:
                            try:
                                more_reply_button = await reply_section.query_selector(selector)
                                if more_reply_button:
                                    print(f"ë”ë³´ê¸° ë²„íŠ¼ ë°œê²¬ (ì„ íƒì: {selector})")
                                    break
                            except:
                                continue
                        
                        # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­
                        if more_reply_button:
                            try:
                                aria_expanded = await more_reply_button.get_attribute('aria-expanded')
                                button_text = await more_reply_button.text_content()
                                print(f"ë²„íŠ¼ ìƒíƒœ - aria-expanded: {aria_expanded}, í…ìŠ¤íŠ¸: {button_text}")
                                
                                if aria_expanded == 'false' or (button_text and 'ë”ë³´ê¸°' in button_text):
                                    print("ë‹µê¸€ ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì¤‘...")
                                    await more_reply_button.click()
                                    await page.wait_for_timeout(1500)
                                    print("ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
                            except Exception as button_error:
                                print(f"ë²„íŠ¼ í´ë¦­ ì¤‘ ì˜¤ë¥˜: {button_error}")
                        
                        # ë‹µê¸€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        reply_text = await reply_text_container.text_content()
                        if reply_text:
                            cleaned_reply = reply_text.strip()
                            if cleaned_reply and len(cleaned_reply) > 10:
                                print(f"ì‚¬ì—…ì ë‹µê¸€ ì¶”ì¶œ ì™„ë£Œ ({len(cleaned_reply)}ì): {cleaned_reply[:100]}...")
                                result['reply_text'] = cleaned_reply
                
                return result
            
            # 3. ë‹µê¸€ ë²„íŠ¼ì´ ì—†ëŠ” ê²½ìš° - ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ ë‹µê¸€ ì„¹ì…˜ í™•ì¸
            reply_section_selectors = [
                ".pui__GbW8H7.pui__BDGQvd",
                ".pui__GbW8H7",
            ]
            
            for selector in reply_section_selectors:
                try:
                    reply_section = await review_element.query_selector(selector)
                    if reply_section:
                        # ë‹µê¸€ ì„¹ì…˜ì´ ìˆìœ¼ë©´ sentë¡œ ê°„ì£¼
                        print(f"ë‹µê¸€ ì„¹ì…˜ ë°œê²¬ - reply_status: sent (ë²„íŠ¼ ì—†ìŒ)")
                        result['reply_status'] = 'sent'
                        
                        # ë‹µê¸€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìœ„ì˜ ë¡œì§ ì¬ì‚¬ìš©)
                        reply_text_container = await reply_section.query_selector("a[data-pui-click-code='rv.replyfold']")
                        if reply_text_container:
                            reply_text = await reply_text_container.text_content()
                            if reply_text:
                                cleaned_reply = reply_text.strip()
                                if cleaned_reply and len(cleaned_reply) > 10:
                                    result['reply_text'] = cleaned_reply
                        break
                except:
                    continue
            
            # ë‹µê¸€ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ì—†ëŠ” ê²½ìš°
            if result['reply_status'] is None:
                print("âš ï¸ ë‹µê¸€ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŒ")
            
            return result
            
        except Exception as e:
            print(f"ì‚¬ì—…ì ë‹µê¸€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {'reply_text': None, 'reply_status': None}
    
    async def _check_receipt(self, review_element) -> bool:
        """ì˜ìˆ˜ì¦ ì²¨ë¶€ ì—¬ë¶€ í™•ì¸"""
        try:
            receipt_element = await review_element.query_selector(".pui__lHDwSH")
            if receipt_element:
                receipt_text = await receipt_element.text_content()
                return 'ì˜ìˆ˜ì¦' in receipt_text
            return False
            
        except Exception as e:
            print(f"ì˜ìˆ˜ì¦ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
    
    async def _generate_review_id(self, review_element) -> str:
        """ë„¤ì´ë²„ ë¦¬ë·° ê³ ìœ  ID ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: ê²°ì œ ì •ë³´ ë§í¬ì—ì„œ ë¦¬ë·° ID ì¶”ì¶œ
            # ì˜ˆ: https://m.place.naver.com/my/review/689f2e547d44f69239bcf8e3/paymentInfo#showReceipt
            payment_link = await review_element.query_selector("a[data-pui-click-code='rv.paymentinfo']")
            if payment_link:
                href = await payment_link.get_attribute('href')
                print(f"ê²°ì œ ì •ë³´ ë§í¬ ë°œê²¬: {href}")
                
                if href and '/my/review/' in href:
                    # URLì—ì„œ ë¦¬ë·° ID ì¶”ì¶œ
                    # /my/review/689f2e547d44f69239bcf8e3/paymentInfo í˜•íƒœì—ì„œ ID ì¶”ì¶œ
                    import re
                    match = re.search(r'/my/review/([a-f0-9]+)/', href)
                    if match:
                        review_id = match.group(1)
                        print(f"âœ… ë„¤ì´ë²„ ë¦¬ë·° ID ì¶”ì¶œ ì„±ê³µ: {review_id}")
                        return review_id
                    
                    # ëŒ€ì²´ ë°©ë²•: splitìœ¼ë¡œ ì¶”ì¶œ
                    parts = href.split('/my/review/')
                    if len(parts) > 1:
                        review_id = parts[1].split('/')[0]
                        # #showReceipt ê°™ì€ í•´ì‹œ ì œê±°
                        review_id = review_id.split('#')[0]
                        if review_id and len(review_id) == 24:  # ë„¤ì´ë²„ ë¦¬ë·° IDëŠ” ë³´í†µ 24ì
                            print(f"âœ… ë„¤ì´ë²„ ë¦¬ë·° ID ì¶”ì¶œ ì„±ê³µ (split ë°©ë²•): {review_id}")
                            return review_id
            else:
                print("âš ï¸ ê²°ì œ ì •ë³´ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (ì˜ìˆ˜ì¦ì´ ì—†ëŠ” ë¦¬ë·°)")
            
            # ë°©ë²• 2: ì˜ìˆ˜ì¦ì´ ì—†ëŠ” ë¦¬ë·°ì˜ ê²½ìš° ê³ ìœ  ID ìƒì„±
            # ë¦¬ë·° ì‘ì„±ì¼ + ì‚¬ìš©ì ì •ë³´ + ë¦¬ë·° í…ìŠ¤íŠ¸ë¡œ ê³ ìœ  ID ìƒì„±
            import hashlib
            
            # ì‘ì„±ì¼ ì¶”ì¶œ
            date_element = await review_element.query_selector(".pui__4rEbt5 time")
            date_text = ""
            if date_element:
                date_text = await date_element.text_content()
            
            # ì‚¬ìš©ì ì´ë¦„ ì¶”ì¶œ
            reviewer_name = ""
            name_element = await review_element.query_selector(".pui__NMi-Dp")
            if name_element:
                reviewer_name = await name_element.text_content()
            
            # ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì²˜ìŒ 100ì)
            review_text = ""
            text_element = await review_element.query_selector("a.pui__xtsQN-")
            if text_element:
                review_text = await text_element.text_content()
                review_text = review_text[:100] if review_text else ""
            
            # í”„ë¡œí•„ URLì—ì„œ ì‚¬ìš©ì ID ì¶”ì¶œ
            user_id = ""
            profile_link = await review_element.query_selector("a[data-pui-click-code='profile']")
            if profile_link:
                href = await profile_link.get_attribute('href')
                if href and '/my/' in href:
                    parts = href.split('/my/')
                    if len(parts) > 1:
                        user_id = parts[1].split('/')[0]
            
            # ê³ ìœ  ID ìƒì„±
            if user_id and (date_text or review_text):
                # ì‚¬ìš©ì ID + ë‚ ì§œ + ë¦¬ë·° í…ìŠ¤íŠ¸ ì¡°í•©
                unique_string = f"{user_id}_{date_text}_{review_text[:50]}"
                review_id = hashlib.md5(unique_string.encode()).hexdigest()[:24]
                print(f"ğŸ”§ ë„¤ì´ë²„ ë¦¬ë·° ID ìƒì„± (ì˜ìˆ˜ì¦ ì—†ëŠ” ë¦¬ë·°): {review_id}")
                return review_id
            elif reviewer_name and date_text and review_text:
                # ì‚¬ìš©ì ì´ë¦„ + ë‚ ì§œ + ë¦¬ë·° í…ìŠ¤íŠ¸ ì¡°í•©
                unique_string = f"{reviewer_name}_{date_text}_{review_text[:50]}"
                review_id = hashlib.md5(unique_string.encode()).hexdigest()[:24]
                print(f"ğŸ”§ ë„¤ì´ë²„ ë¦¬ë·° ID ìƒì„± (ì´ë¦„ ê¸°ë°˜): {review_id}")
                return review_id
            
            # ë°©ë²• 3: ë¦¬ë·° ìš”ì†Œì˜ data ì†ì„± í™•ì¸
            # ì¼ë¶€ í˜ì´ì§€ì—ì„œëŠ” data-review-id ê°™ì€ ì†ì„±ì´ ìˆì„ ìˆ˜ ìˆìŒ
            data_attrs = await review_element.evaluate("el => Object.keys(el.dataset)")
            for attr in data_attrs:
                if 'review' in attr.lower() or 'id' in attr.lower():
                    value = await review_element.evaluate(f"el => el.dataset['{attr}']")
                    if value:
                        print(f"ë„¤ì´ë²„ ë¦¬ë·° ID ì¶”ì¶œ ì„±ê³µ (data ì†ì„±): {value}")
                        return value
            
            # í´ë°±: í•´ì‹œ ê¸°ë°˜ ê³ ìœ  ID ìƒì„±
            import hashlib
            text_element = await review_element.query_selector("a.pui__xtsQN-")
            if text_element:
                text_content = await text_element.text_content()
                review_id = hashlib.md5(text_content.encode()).hexdigest()[:24]
                print(f"ë„¤ì´ë²„ ë¦¬ë·° ID ìƒì„± (í…ìŠ¤íŠ¸ í•´ì‹œ): {review_id}")
                return review_id
            
            # ìµœì¢… í´ë°±
            fallback_id = f"review_{int(datetime.now().timestamp() * 1000)}"
            print(f"ë„¤ì´ë²„ ë¦¬ë·° ID ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„): {fallback_id}")
            return fallback_id
            
        except Exception as e:
            print(f"ë¦¬ë·° ID ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return f"review_{int(datetime.now().timestamp() * 1000)}"
    
    async def _extract_reviewer_name(self, review_element) -> str:
        """ë¦¬ë·°ì–´ ì´ë¦„ë§Œ ë¹ ë¥´ê²Œ ì¶”ì¶œ (ID ìƒì„±ìš©)"""
        try:
            name_element = await review_element.query_selector(".pui__NMi-Dp")
            if name_element:
                return await name_element.text_content()
            return ""
        except:
            return ""
    
    async def _extract_review_text_for_id(self, review_element) -> str:
        """ë¦¬ë·° í…ìŠ¤íŠ¸ë§Œ ë¹ ë¥´ê²Œ ì¶”ì¶œ (ID ìƒì„±ìš©)"""
        try:
            text_element = await review_element.query_selector("a.pui__xtsQN-")
            if text_element:
                return await text_element.text_content()
            return ""
        except:
            return ""
    
    def _extract_number(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        import re
        numbers = re.findall(r'\d+', text)
        return int(numbers[0]) if numbers else 0
    
    def _parse_date(self, date_text: str) -> str:
        """ë‚ ì§œ í…ìŠ¤íŠ¸ íŒŒì‹±"""
        try:
            # "2025. 8. 5(í™”)" í˜•íƒœë¥¼ "2025-08-05" í˜•íƒœë¡œ ë³€í™˜
            import re
            date_match = re.search(r'(\d{4})\.\s*(\d{1,2})\.\s*(\d{1,2})', date_text)
            if date_match:
                year, month, day = date_match.groups()
                return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
            return date_text
            
        except Exception as e:
            print(f"ë‚ ì§œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return date_text
    
    async def _process_review_results(self, reviews: List[Dict], store_id: str, user_id: str) -> Dict:
        """ë¦¬ë·° ê²°ê³¼ ì²˜ë¦¬ ë° Supabase reviews_naver í…Œì´ë¸”ì— ì €ì¥"""
        try:
            reviews_found = len(reviews)
            reviews_new = 0
            reviews_updated = 0
            
            if reviews_found == 0:
                print("ìˆ˜ì§‘ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    'success': True,
                    'reviews_found': 0,
                    'reviews_new': 0,
                    'reviews_updated': 0,
                    'table_used': 'reviews_naver'
                }
            
            # platform_store_id ì¡°íšŒ
            platform_store_result = self.supabase.table('platform_stores').select('id').eq('user_id', user_id).eq('platform_store_id', store_id).eq('platform', 'naver').single().execute()
            
            if not platform_store_result.data:
                print(f"platform_stores í…Œì´ë¸”ì—ì„œ store_id {store_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    'success': False,
                    'error': f'Store not found in platform_stores: {store_id}',
                    'reviews_found': reviews_found,
                    'reviews_new': 0,
                    'reviews_updated': 0
                }
            
            platform_store_uuid = platform_store_result.data['id']
            print(f"Platform store UUID: {platform_store_uuid}")
            
            # ê¸°ì¡´ ë¦¬ë·° í™•ì¸ (ì¤‘ë³µ ë°©ì§€)
            existing_reviews_result = self.supabase.table('reviews_naver').select('naver_review_id').eq('platform_store_id', platform_store_uuid).execute()
            existing_review_ids = {review['naver_review_id'] for review in existing_reviews_result.data}
            
            print(f"ê¸°ì¡´ ë¦¬ë·° ìˆ˜: {len(existing_review_ids)}")
            
            # ìƒˆë¡œìš´ ë¦¬ë·°ë§Œ í•„í„°ë§í•˜ì—¬ ë°ì´í„° ë³€í™˜
            new_reviews_data = []
            for review in reviews:
                naver_review_id = review.get('review_id', '')
                
                # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë¦¬ë·°ì¸ì§€ í™•ì¸
                if naver_review_id in existing_review_ids:
                    print(f"ì¤‘ë³µ ë¦¬ë·° ê±´ë„ˆë›°ê¸°: {naver_review_id}")
                    continue
                
                # reviews_naver í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ë³€í™˜ (ì‹¤ì œ ìŠ¤í‚¤ë§ˆì— ë§ì¶¤)
                # ë¦¬ë·°ì–´ í†µê³„ì—ì„œ ë ˆë²¨ ì¶”ì¶œ
                reviewer_stats = review.get('reviewer_stats', {})
                reviewer_level = f"ë¦¬ë·° {reviewer_stats.get('review_count', 0)}" if reviewer_stats else None
                
                # í‚¤ì›Œë“œë¥¼ JSONB í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                keywords_list = review.get('keywords', [])
                extracted_keywords_jsonb = json.dumps(keywords_list, ensure_ascii=False) if keywords_list else '[]'
                
                # naver_metadataì— reviewer_stats í¬í•¨
                naver_metadata = {
                    'images': review.get('images', []),
                    'keywords': review.get('keywords', []),
                    'has_receipt': review.get('has_receipt', False),
                    'visit_date': review.get('visit_date', ''),
                    'reviewer_profile_url': review.get('reviewer_profile_url', ''),
                    'reviewer_stats': reviewer_stats,  # ì—¬ê¸°ì— í†µê³„ ì •ë³´ ì €ì¥
                    'crawled_at': datetime.now().isoformat()
                }
                
                review_data = {
                    'platform_store_id': platform_store_uuid,
                    'naver_review_id': naver_review_id,
                    'naver_review_url': f"https://new.smartplace.naver.com/bizes/place/{store_id}/reviews",
                    'reviewer_name': review.get('reviewer_name', ''),
                    'reviewer_id': review.get('reviewer_profile_url', '').split('/')[-1] if review.get('reviewer_profile_url') else '',
                    'reviewer_level': reviewer_level,  # reviewer_stats ëŒ€ì‹  reviewer_level ì‚¬ìš©
                    'rating': review.get('rating') if review.get('rating') else None,
                    'review_text': review.get('review_text', ''),
                    'review_date': review.get('created_date', ''),
                    'reply_text': review.get('reply_text'),  # ì‚¬ì—…ì ë‹µê¸€ í…ìŠ¤íŠ¸
                    'reply_status': review.get('reply_status'),  # ë‹µê¸€ ìƒíƒœ (pending/completed/None)
                    'has_photos': len(review.get('images', [])) > 0,
                    'photo_count': len(review.get('images', [])),
                    'is_visited_review': review.get('has_receipt', False),  # ì˜ìˆ˜ì¦ = ë°©ë¬¸ ì¸ì¦
                    'extracted_keywords': extracted_keywords_jsonb,  # JSONB í˜•ì‹
                    'naver_metadata': json.dumps(naver_metadata, ensure_ascii=False),  # JSONB í˜•ì‹
                    'created_at': datetime.now().isoformat(),
                    'updated_at': datetime.now().isoformat()
                }
                new_reviews_data.append(review_data)
            
            reviews_new = len(new_reviews_data)
            
            if reviews_new == 0:
                print("ëª¨ë“  ë¦¬ë·°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìƒˆë¡œ ì €ì¥í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    'success': True,
                    'reviews_found': reviews_found,
                    'reviews_new': 0,
                    'reviews_updated': 0,
                    'message': 'All reviews already exist',
                    'table_used': 'reviews_naver'
                }
            
            # Supabaseì— ìƒˆ ë¦¬ë·°ë“¤ ì¼ê´„ ì‚½ì…
            print(f"Supabaseì— {reviews_new}ê°œì˜ ìƒˆ ë¦¬ë·° ì €ì¥ ì¤‘...")
            insert_result = self.supabase.table('reviews_naver').insert(new_reviews_data).execute()
            
            if insert_result.data:
                print(f"ì„±ê³µì ìœ¼ë¡œ {len(insert_result.data)}ê°œì˜ ë¦¬ë·°ë¥¼ Supabaseì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                
                # platform_stores í…Œì´ë¸”ì˜ last_crawled_at ì—…ë°ì´íŠ¸ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©)
                try:
                    self.supabase.table('platform_stores').update({
                        'last_crawled_at': datetime.now().isoformat()
                    }).eq('id', platform_store_uuid).execute()
                    print("platform_stores í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                except Exception as update_error:
                    print(f"platform_stores ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {str(update_error)}")
                
                return {
                    'success': True,
                    'reviews_found': reviews_found,
                    'reviews_new': reviews_new,
                    'reviews_updated': reviews_updated,
                    'table_used': 'reviews_naver',
                    'platform_store_id': platform_store_uuid
                }
            else:
                raise Exception("Supabase ì‚½ì… ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            error_msg = f"Supabase ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(error_msg)
            
            # platform_stores ì—…ë°ì´íŠ¸ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ë¦¬ë·° ì €ì¥ ì„±ê³µ ì—¬ë¶€ë§Œ í™•ì¸
            if "Could not find the 'naver_last_crawl" in str(e) and reviews_new > 0:
                print("platform_stores ìŠ¤í‚¤ë§ˆ ì˜¤ë¥˜ì´ì§€ë§Œ ë¦¬ë·° ì €ì¥ì€ ì„±ê³µ - success=True ë°˜í™˜")
                return {
                    'success': True,
                    'reviews_found': reviews_found,
                    'reviews_new': reviews_new,
                    'reviews_updated': reviews_updated,
                    'table_used': 'reviews_naver',
                    'platform_store_id': platform_store_uuid,
                    'warning': 'platform_stores ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ìŠ¤í‚¤ë§ˆ ì˜¤ë¥˜)'
                }
            
            # ì˜¤ë¥˜ ë°œìƒì‹œ platform_stores í…Œì´ë¸”ì— ì˜¤ë¥˜ ì •ë³´ ê¸°ë¡ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©)
            try:
                if 'platform_store_uuid' in locals():
                    self.supabase.table('platform_stores').update({
                        'last_crawled_at': datetime.now().isoformat()
                    }).eq('id', platform_store_uuid).execute()
            except:
                pass
            
            return {
                'success': False,
                'error': error_msg,
                'reviews_found': reviews_found,
                'reviews_new': 0,
                'reviews_updated': 0
            }

async def main():
    parser = argparse.ArgumentParser(description='ë„¤ì´ë²„ ë¦¬ë·° í¬ë¡¤ë§')
    parser.add_argument('--email', required=True, help='ë„¤ì´ë²„ ì´ë©”ì¼/ì•„ì´ë””')
    parser.add_argument('--password', required=True, help='ë„¤ì´ë²„ ë¹„ë°€ë²ˆí˜¸')
    parser.add_argument('--store-id', required=True, help='ë§¤ì¥ ID (platform_store_id)')
    parser.add_argument('--user-id', required=True, help='ì‚¬ìš©ì ID (UUID)')
    parser.add_argument('--days', type=int, default=7, help='í¬ë¡¤ë§ ê¸°ê°„ (ì¼)')
    parser.add_argument('--mode', default='auto', help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--headless', action='store_true', help='í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ')
    parser.add_argument('--timeout', type=int, default=30000, help='íƒ€ì„ì•„ì›ƒ (ms)')
    parser.add_argument('--force-fresh', action='store_true', help='ê¸°ì¡´ ì„¸ì…˜ ë¬´ì‹œí•˜ê³  ê°•ì œ ìƒˆ ë¡œê·¸ì¸')
    
    args = parser.parse_args()
    
    crawler = NaverReviewCrawler(
        headless=args.headless, 
        timeout=args.timeout,
        force_fresh_login=args.force_fresh
    )
    result = await crawler.crawl_reviews(
        args.email, 
        args.password, 
        args.store_id,
        args.user_id, 
        args.days
    )
    
    # ê²°ê³¼ ì¶œë ¥ (JSON í˜•íƒœ)
    print(f"CRAWLING_RESULT:{json.dumps(result, ensure_ascii=False)}")
    
    return result['success']

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)